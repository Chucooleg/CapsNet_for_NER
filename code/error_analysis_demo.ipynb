{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load this section first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/yeunghoman/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import evaluation_helper\n",
    "from loadutils import construct_embedding_matrix\n",
    "from loadutils import conll2003Data, loadDevPredictionsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE = \"../data/CoNLL-2003_NeuroNER/en/train.txt\"\n",
    "DEV_FILE = \"../data/CoNLL-2003_NeuroNER/en/valid.txt\"\n",
    "TEST_FILE = \"../data/CoNLL-2003_NeuroNER/en/test.txt\"\n",
    "DEV_LABELS = \"eval_labels/devY.npy\"\n",
    "TEST_LABELS = \"eval_labels/testY.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo  - Quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rank 1\n",
      "modelName: glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_base\n",
      "f1= 0.92111423221\n",
      "\n",
      "rank 2\n",
      "modelName: glove50_learn_drop50_decode1000_caps3_conv5_cos_win7_pos_caps\n",
      "f1= 0.918615639027\n",
      "\n",
      "rank 3\n",
      "modelName: glove50_learn_drop50_decode1000_caps3_conv5_cos_win7_base\n",
      "f1= 0.918493271434\n",
      "\n",
      "rank 4\n",
      "modelName: glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_pos_caps\n",
      "f1= 0.916107777386\n",
      "------------------------------------------------------------\n",
      "Model Name : glove_learn_dropout_pos_caps\n",
      "F1 Score   : 0.9021899533675697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.90218995336756969"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation_helper import get_f1_by_modelName, compare_models_by_f1\n",
    "\n",
    "devY = np.load(DEV_LABELS)\n",
    "testY = np.load(TEST_LABELS)\n",
    "\n",
    "modelName_list = ['glove50_learn_drop50_decode1000_caps3_conv5_cos_win7_pos_caps', \\\n",
    "                  'glove50_learn_drop50_decode1000_caps3_conv5_cos_win7_base', \\\n",
    "                  'glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_base', \\\n",
    "                  'glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_pos_caps']\n",
    "compare_models_by_f1(modelName_list, y_true=devY, return_results=False)\n",
    "\n",
    "print (\"------------------------------------------------------------\")\n",
    "modelName1 = 'glove_learn_dropout_pos_caps'\n",
    "get_f1_by_modelName(modelName1, y_true=devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo  - Full Report for one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelName = 'glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_base'\n",
    "\n",
    "global_max_features = 20000\n",
    "windowLength = 9\n",
    "global_embed_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just load this (30 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "reading file from path ../data/CoNLL-2003_NeuroNER/en/train.txt\n",
      "'readFile'  1207.47 ms\n",
      "----------------------------------------------------\n",
      "building vocabulary from TRAINING data...\n",
      "'buildVocab'  1123.93 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  1889.00 ms\n",
      "----------------------------------------------------\n",
      "reading file from path ../data/CoNLL-2003_NeuroNER/en/valid.txt\n",
      "'readFile'  277.68 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  451.96 ms\n",
      "----------------------------------------------------\n",
      "reading file from path ../data/CoNLL-2003_NeuroNER/en/test.txt\n",
      "'readFile'  248.99 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  548.11 ms\n",
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.50d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 50))\n"
     ]
    }
   ],
   "source": [
    "# Use training set to build vocab here\n",
    "vocabData = conll2003Data(TRAIN_FILE)\n",
    "vocabData.buildVocab( vocabSize=global_max_features)\n",
    "\n",
    "# Format training data\n",
    "trainX, trainX_pos, trainX_capitals, trainY  = vocabData.formatWindowedData( \n",
    "                                                  vocabData.train_sentences, \n",
    "                                                  windowLength=windowLength,\n",
    "                                                  verbose=False)\n",
    "\n",
    "# read in dev data\n",
    "devSents = vocabData.readFile( DEV_FILE)\n",
    "devX, devX_pos, devX_capitals, devY = vocabData.formatWindowedData( \n",
    "                                              devSents, \n",
    "                                              windowLength=windowLength,\n",
    "                                              verbose=False)\n",
    "\n",
    "# read in the test data\n",
    "testSents = vocabData.readFile( TEST_FILE)\n",
    "testX, testX_pos, testX_capitals, testY = vocabData.formatWindowedData( \n",
    "                                                testSents, \n",
    "                                                windowLength=windowLength,\n",
    "                                                verbose=False)\n",
    "\n",
    "# load embeddings\n",
    "embedding_matrix = construct_embedding_matrix( global_embed_dim, \n",
    "                                               global_max_features, vocabData)\n",
    "\n",
    "\n",
    "# Get decoder Y -- 50 dim embedding of center word\n",
    "train_decoderY = embedding_matrix[trainX[:,4]]\n",
    "dev_decoderY = embedding_matrix[devX[:,4]]\n",
    "test_decoderY = embedding_matrix[testX[:,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw_y_pred, dev_raw_y_pred_decoder_embeddings, dev_y_pred = loadDevPredictionsData(modelName)\n",
    "\n",
    "# construct report object\n",
    "report_obj = evaluation_helper.EvalDev_Report(modelName=modelName, y_true=devY, raw_y_pred=dev_raw_y_pred, y_pred=dev_y_pred, \\\n",
    "                                              y_true_decoder=dev_decoderY, y_pred_decoder=dev_raw_y_pred_decoder_embeddings) \n",
    "report_obj.connect_to_dataClass(vocabData)\n",
    "report_obj.connect_to_devData(devData=(devX, devX_pos, devX_capitals, devY))\n",
    "report_obj.connect_to_embeddding_matrix(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print full report here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------BRIEF SUMMARY-------------------------\n",
      "\n",
      "Model     glove50_learn_drop50_decode1000_caps3_conv3_cos_win7_base\n",
      "Precision 0.9275191514437242\n",
      "Recall    0.9147971637800767\n",
      "f1 score  0.9211142322097379\n",
      "\n",
      "Gold NER label counts:\n",
      "42759 : ['O'] (tag3)\n",
      "1341 : ['B-ORG'] (tag6)\n",
      "1837 : ['B-LOC'] (tag4)\n",
      "922 : ['B-MISC'] (tag9)\n",
      "346 : ['I-MISC'] (tag11)\n",
      "1842 : ['B-PER'] (tag5)\n",
      "1307 : ['I-PER'] (tag7)\n",
      "257 : ['I-LOC'] (tag10)\n",
      "751 : ['I-ORG'] (tag8)\n",
      "\n",
      "Predicted NER label counts:\n",
      "42877 : ['O'] (tag3)\n",
      "1333 : ['B-ORG'] (tag6)\n",
      "1891 : ['B-LOC'] (tag4)\n",
      "866 : ['B-MISC'] (tag9)\n",
      "272 : ['I-MISC'] (tag11)\n",
      "1886 : ['B-PER'] (tag5)\n",
      "1307 : ['I-PER'] (tag7)\n",
      "273 : ['I-LOC'] (tag10)\n",
      "657 : ['I-ORG'] (tag8)\n",
      "\n",
      "----------------GOLD to PREDICTION LABELS COUNTS---------------\n",
      "\n",
      "\n",
      "Gold label \"['O']\" (tag3), prediction label counts:\n",
      "42633 (0.9973%): \"['O']\" (tag3)\n",
      "14 (0.0003%): \"['B-LOC']\" (tag4)\n",
      "23 (0.0005%): \"['B-PER']\" (tag5)\n",
      "33 (0.0008%): \"['B-ORG']\" (tag6)\n",
      "5 (0.0001%): \"['I-PER']\" (tag7)\n",
      "10 (0.0002%): \"['I-ORG']\" (tag8)\n",
      "31 (0.0007%): \"['B-MISC']\" (tag9)\n",
      "1 (0.0%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-LOC']\" (tag4), prediction label counts:\n",
      "12 (0.0065%): \"['O']\" (tag3)\n",
      "1777 (0.9673%): \"['B-LOC']\" (tag4)\n",
      "13 (0.0071%): \"['B-PER']\" (tag5)\n",
      "25 (0.0136%): \"['B-ORG']\" (tag6)\n",
      "0 (0.0%): \"['I-PER']\" (tag7)\n",
      "1 (0.0005%): \"['I-ORG']\" (tag8)\n",
      "7 (0.0038%): \"['B-MISC']\" (tag9)\n",
      "2 (0.0011%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-PER']\" (tag5), prediction label counts:\n",
      "16 (0.0087%): \"['O']\" (tag3)\n",
      "27 (0.0147%): \"['B-LOC']\" (tag4)\n",
      "1768 (0.9598%): \"['B-PER']\" (tag5)\n",
      "24 (0.013%): \"['B-ORG']\" (tag6)\n",
      "3 (0.0016%): \"['I-PER']\" (tag7)\n",
      "1 (0.0005%): \"['I-ORG']\" (tag8)\n",
      "3 (0.0016%): \"['B-MISC']\" (tag9)\n",
      "0 (0.0%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-ORG']\" (tag6), prediction label counts:\n",
      "16 (0.0119%): \"['O']\" (tag3)\n",
      "36 (0.0268%): \"['B-LOC']\" (tag4)\n",
      "47 (0.035%): \"['B-PER']\" (tag5)\n",
      "1197 (0.8926%): \"['B-ORG']\" (tag6)\n",
      "3 (0.0022%): \"['I-PER']\" (tag7)\n",
      "6 (0.0045%): \"['I-ORG']\" (tag8)\n",
      "35 (0.0261%): \"['B-MISC']\" (tag9)\n",
      "1 (0.0007%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-PER']\" (tag7), prediction label counts:\n",
      "19 (0.0145%): \"['O']\" (tag3)\n",
      "0 (0.0%): \"['B-LOC']\" (tag4)\n",
      "9 (0.0069%): \"['B-PER']\" (tag5)\n",
      "2 (0.0015%): \"['B-ORG']\" (tag6)\n",
      "1265 (0.9679%): \"['I-PER']\" (tag7)\n",
      "0 (0.0%): \"['I-ORG']\" (tag8)\n",
      "0 (0.0%): \"['B-MISC']\" (tag9)\n",
      "12 (0.0092%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-ORG']\" (tag8), prediction label counts:\n",
      "42 (0.0568%): \"['O']\" (tag3)\n",
      "12 (0.0162%): \"['B-LOC']\" (tag4)\n",
      "2 (0.0027%): \"['B-PER']\" (tag5)\n",
      "16 (0.0217%): \"['B-ORG']\" (tag6)\n",
      "26 (0.0352%): \"['I-PER']\" (tag7)\n",
      "619 (0.8376%): \"['I-ORG']\" (tag8)\n",
      "1 (0.0014%): \"['B-MISC']\" (tag9)\n",
      "21 (0.0284%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-MISC']\" (tag9), prediction label counts:\n",
      "76 (0.0827%): \"['O']\" (tag3)\n",
      "19 (0.0207%): \"['B-LOC']\" (tag4)\n",
      "23 (0.025%): \"['B-PER']\" (tag5)\n",
      "32 (0.0348%): \"['B-ORG']\" (tag6)\n",
      "1 (0.0011%): \"['I-PER']\" (tag7)\n",
      "1 (0.0011%): \"['I-ORG']\" (tag8)\n",
      "767 (0.8346%): \"['B-MISC']\" (tag9)\n",
      "0 (0.0%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-LOC']\" (tag10), prediction label counts:\n",
      "9 (0.0356%): \"['O']\" (tag3)\n",
      "4 (0.0158%): \"['B-LOC']\" (tag4)\n",
      "0 (0.0%): \"['B-PER']\" (tag5)\n",
      "1 (0.004%): \"['B-ORG']\" (tag6)\n",
      "0 (0.0%): \"['I-PER']\" (tag7)\n",
      "6 (0.0237%): \"['I-ORG']\" (tag8)\n",
      "0 (0.0%): \"['B-MISC']\" (tag9)\n",
      "233 (0.9209%): \"['I-LOC']\" (tag10)\n",
      "\n",
      "-------------------------WORST OVERALL-------------------------\n",
      "\n",
      "indices counts = 51362\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 4140\n",
      "KL divergence 6.729206085205078\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', 'thursday', 'as']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', 'NNP', 'IN']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'upperInitial', 'lowercase']\n",
      "\n",
      "ID 34600\n",
      "KL divergence 6.604596138000488\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', '.', '</s>']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', '.', '</s>']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', '</s>']\n",
      "\n",
      "-------------------WORST NER LABEL MISMATCH--------------------\n",
      "\n",
      "indices counts = 489\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 33636\n",
      "KL divergence 6.47977352142334\n",
      "FEATURES:   \"beograd\", NNP, upperInitial\n",
      "Gold NER    ['I-MISC']\n",
      "Pred NER    ['I-ORG']\n",
      "Text window ['results', 'in', 'the', '<unk>', 'beograd', 'DGDG', '</s>', '</s>', '</s>']\n",
      "PoS window  ['NNS', 'IN', 'DT', 'NNP', 'NNP', 'CD', '</s>', '</s>', '</s>']\n",
      "Caps window ['upperInitial', 'lowercase', 'lowercase', 'upperInitial', 'upperInitial', 'noinfo', '</s>', '</s>', '</s>']\n",
      "\n",
      "ID 33691\n",
      "KL divergence 6.47977352142334\n",
      "FEATURES:   \"beograd\", NNP, upperInitial\n",
      "Gold NER    ['I-MISC']\n",
      "Pred NER    ['I-ORG']\n",
      "Text window ['results', 'in', 'the', '<unk>', 'beograd', 'DGDG', '</s>', '</s>', '</s>']\n",
      "PoS window  ['NNS', 'IN', 'DT', 'NNP', 'NNP', 'CD', '</s>', '</s>', '</s>']\n",
      "Caps window ['upperInitial', 'lowercase', 'lowercase', 'upperInitial', 'upperInitial', 'noinfo', '</s>', '</s>', '</s>']\n",
      "\n",
      "----------------WORST NER PREDICTION BY LABEL------------------\n",
      "\n",
      "----------------------------\n",
      "Label O (tag3)\n",
      "indices counts = 42750\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 28093\n",
      "KL divergence 4.733577251434326\n",
      "FEATURES:   \"pakistan\", SYM, lowercase\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['B-LOC']\n",
      "Text window ['<s>', '<s>', '<s>', '<s>', 'pakistan', '</s>', '</s>', '</s>', '</s>']\n",
      "PoS window  ['<s>', '<s>', '<s>', '<s>', 'SYM', '</s>', '</s>', '</s>', '</s>']\n",
      "Caps window ['<s>', '<s>', '<s>', '<s>', 'lowercase', '</s>', '</s>', '</s>', '</s>']\n",
      "\n",
      "ID 9299\n",
      "KL divergence 4.366549491882324\n",
      "FEATURES:   \"bunds\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['B-MISC']\n",
      "Text window ['<s>', '<s>', 'germany', '-', 'bunds', 'extended', 'losses', ',', '<unk>']\n",
      "PoS window  ['<s>', '<s>', 'JJ', ':', 'NNP', 'VBD', 'NNS', ',', 'VBG']\n",
      "Caps window ['<s>', '<s>', 'allCaps', 'noinfo', 'upperInitial', 'lowercase', 'lowercase', 'noinfo', 'lowercase']\n",
      "----------------------------\n",
      "Label B-LOC (tag4)\n",
      "indices counts = 1837\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 48257\n",
      "KL divergence 6.409413814544678\n",
      "FEATURES:   \"<unk>\", NNP, upperInitial\n",
      "Gold NER    ['B-LOC']\n",
      "Pred NER    ['B-MISC']\n",
      "Text window ['day', 'weekend', ',', 'including', '<unk>', 'DGDG', 'on', 'the', 'east']\n",
      "PoS window  ['NNP', 'NN', ',', 'VBG', 'NNP', 'NNP', 'IN', 'DT', 'NNP']\n",
      "Caps window ['upperInitial', 'lowercase', 'noinfo', 'lowercase', 'upperInitial', 'noinfo', 'lowercase', 'lowercase', 'upperInitial']\n",
      "\n",
      "ID 48267\n",
      "KL divergence 5.538806438446045\n",
      "FEATURES:   \"DGDG\", CD, noinfo\n",
      "Gold NER    ['B-LOC']\n",
      "Pred NER    ['O']\n",
      "Text window [',', '<unk>', 'DGDG', 'and', 'DGDG', 'in', 'the', 'midwest', 'and']\n",
      "PoS window  [',', 'NNP', 'CD', 'CC', 'CD', 'IN', 'DT', 'NNP', 'CC']\n",
      "Caps window ['noinfo', 'upperInitial', 'noinfo', 'lowercase', 'noinfo', 'lowercase', 'lowercase', 'upperInitial', 'lowercase']\n",
      "----------------------------\n",
      "Label B-PER (tag5)\n",
      "indices counts = 1842\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 37644\n",
      "KL divergence 5.901582717895508\n",
      "FEATURES:   \"<unk>\", NNP, allCaps\n",
      "Gold NER    ['B-PER']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', '<unk>', '-', 'prince', '<unk>', '<unk>', '<unk>', '<unk>', 'title']\n",
      "PoS window  ['<s>', 'VBG', ':', 'NNP', 'NNP', 'NNS', 'IN', 'NN', 'NN']\n",
      "Caps window ['<s>', 'allCaps', 'noinfo', 'allCaps', 'allCaps', 'allCaps', 'allCaps', 'allCaps', 'allCaps']\n",
      "\n",
      "ID 224\n",
      "KL divergence 5.35451602935791\n",
      "FEATURES:   \"such\", JJ, upperInitial\n",
      "Gold NER    ['B-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['<unk>', 'advantage', 'but', 'off-spinner', 'such', 'had', '<unk>', 'their', 'hopes']\n",
      "PoS window  ['JJ', 'NN', 'CC', 'JJ', 'JJ', 'VBD', 'VBN', 'PRP$', 'NNS']\n",
      "Caps window ['noinfo', 'lowercase', 'lowercase', 'noinfo', 'upperInitial', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label B-ORG (tag6)\n",
      "indices counts = 1341\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 32295\n",
      "KL divergence 5.871374130249023\n",
      "FEATURES:   \"all\", DT, upperInitial\n",
      "Gold NER    ['B-ORG']\n",
      "Pred NER    ['B-MISC']\n",
      "Text window ['and', 'an', 'historic', 'first', 'all', 'black', 'series', 'triumph', 'on']\n",
      "PoS window  ['CC', 'DT', 'JJ', 'JJ', 'DT', 'NNP', 'NN', 'NN', 'IN']\n",
      "Caps window ['lowercase', 'lowercase', 'lowercase', 'lowercase', 'upperInitial', 'upperInitial', 'lowercase', 'lowercase', 'lowercase']\n",
      "\n",
      "ID 49945\n",
      "KL divergence 5.566964149475098\n",
      "FEATURES:   \"der\", NNP, upperInitial\n",
      "Gold NER    ['B-ORG']\n",
      "Pred NER    ['B-PER']\n",
      "Text window ['in', 'DGDGDGDG', ',', 'told', 'der', '<unk>', 'he', 'did', 'not']\n",
      "PoS window  ['IN', 'CD', ',', 'VBD', 'NNP', 'NNP', 'PRP', 'VBD', 'RB']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label I-PER (tag7)\n",
      "indices counts = 1307\n",
      "ranked by worst cross-entropy loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 results\n",
      "\n",
      "ID 40660\n",
      "KL divergence 5.099338054656982\n",
      "FEATURES:   \"i\", PRP, allCaps\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['-', 'belgian', 'king', '<unk>', 'i', 'born', '.', '</s>', '</s>']\n",
      "PoS window  [':', 'JJ', 'NNP', 'NNP', 'PRP', 'VBN', '.', '</s>', '</s>']\n",
      "Caps window ['noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'allCaps', 'lowercase', 'noinfo', '</s>', '</s>']\n",
      "\n",
      "ID 1522\n",
      "KL divergence 5.0842509269714355\n",
      "FEATURES:   \"<unk>\", JJ, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['hands', 'of', 'stone', '\"', '<unk>', 'climbs', 'into', 'the', 'ring']\n",
      "PoS window  ['NNS', 'IN', 'NNP', '\"', 'JJ', 'NNS', 'IN', 'DT', 'NN']\n",
      "Caps window ['upperInitial', 'lowercase', 'upperInitial', 'noinfo', 'upperInitial', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label I-ORG (tag8)\n",
      "indices counts = 739\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 36488\n",
      "KL divergence 5.876728057861328\n",
      "FEATURES:   \"angeles\", NNP, upperInitial\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['I-LOC']\n",
      "Text window ['<s>', '<s>', '<s>', 'los', 'angeles', 'won', 'for', 'the', 'seventh']\n",
      "PoS window  ['<s>', '<s>', '<s>', 'NNP', 'NNP', 'VBD', 'IN', 'DT', 'JJ']\n",
      "Caps window ['<s>', '<s>', '<s>', 'upperInitial', 'upperInitial', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "\n",
      "ID 21815\n",
      "KL divergence 5.6537322998046875\n",
      "FEATURES:   \"<unk>\", NNP, upperInitial\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['B-ORG']\n",
      "Text window ['l.o.', ':', '<unk>', ',', '<unk>', '&', '<unk>', ',', 'detroit']\n",
      "PoS window  ['NNP', ':', 'NNP', ',', 'NNP', 'CC', 'NNP', ',', 'NNP']\n",
      "Caps window ['noinfo', 'noinfo', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo', 'upperInitial']\n",
      "----------------------------\n",
      "Label B-MISC (tag9)\n",
      "indices counts = 919\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 4140\n",
      "KL divergence 6.729206085205078\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', 'thursday', 'as']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', 'NNP', 'IN']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'upperInitial', 'lowercase']\n",
      "\n",
      "ID 34600\n",
      "KL divergence 6.604596138000488\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', '.', '</s>']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', '.', '</s>']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', '</s>']\n",
      "----------------------------\n",
      "Label I-LOC (tag10)\n",
      "indices counts = 253\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 48258\n",
      "KL divergence 5.276744365692139\n",
      "FEATURES:   \"DGDG\", NNP, noinfo\n",
      "Gold NER    ['I-LOC']\n",
      "Pred NER    ['O']\n",
      "Text window ['weekend', ',', 'including', '<unk>', 'DGDG', 'on', 'the', 'east', 'coast']\n",
      "PoS window  ['NN', ',', 'VBG', 'NNP', 'NNP', 'IN', 'DT', 'NNP', 'NNP']\n",
      "Caps window ['lowercase', 'noinfo', 'lowercase', 'upperInitial', 'noinfo', 'lowercase', 'lowercase', 'upperInitial', 'upperInitial']\n",
      "\n",
      "ID 26793\n",
      "KL divergence 4.6201372146606445\n",
      "FEATURES:   \"society\", NNP, upperInitial\n",
      "Gold NER    ['I-LOC']\n",
      "Pred NER    ['I-ORG']\n",
      "Text window ['called', 'the', '<unk>', '<unk>', 'society', '.', '</s>', '</s>', '</s>']\n",
      "PoS window  ['VBD', 'DT', 'NNP', 'JJ', 'NNP', '.', '</s>', '</s>', '</s>']\n",
      "Caps window ['lowercase', 'lowercase', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo', '</s>', '</s>', '</s>']\n",
      "\n",
      "-------------------------HALLUCINATIONS------------------------\n",
      "model predicts a NER label, but gold label shows None\n",
      "\n",
      "indices counts = 126\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 28093\n",
      "KL divergence 4.733577251434326\n",
      "FEATURES:   \"pakistan\", SYM, lowercase\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['B-LOC']\n",
      "Text window ['<s>', '<s>', '<s>', '<s>', 'pakistan', '</s>', '</s>', '</s>', '</s>']\n",
      "PoS window  ['<s>', '<s>', '<s>', '<s>', 'SYM', '</s>', '</s>', '</s>', '</s>']\n",
      "Caps window ['<s>', '<s>', '<s>', '<s>', 'lowercase', '</s>', '</s>', '</s>', '</s>']\n",
      "\n",
      "ID 9299\n",
      "KL divergence 4.366549491882324\n",
      "FEATURES:   \"bunds\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['B-MISC']\n",
      "Text window ['<s>', '<s>', 'germany', '-', 'bunds', 'extended', 'losses', ',', '<unk>']\n",
      "PoS window  ['<s>', '<s>', 'JJ', ':', 'NNP', 'VBD', 'NNS', ',', 'VBG']\n",
      "Caps window ['<s>', '<s>', 'allCaps', 'noinfo', 'upperInitial', 'lowercase', 'lowercase', 'noinfo', 'lowercase']\n",
      "\n",
      "----------------------MISSED NER LABELS------------------------\n",
      "model predicts no NER label, but gold label shows a NER class\n",
      "\n",
      "indices counts = 244\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 4140\n",
      "KL divergence 6.729206085205078\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', 'thursday', 'as']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', 'NNP', 'IN']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'upperInitial', 'lowercase']\n",
      "\n",
      "ID 34600\n",
      "KL divergence 6.604596138000488\n",
      "FEATURES:   \"greater\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', '$', 'DG.DG', 'million', 'greater', 'milwaukee', 'open', '.', '</s>']\n",
      "PoS window  ['DT', '$', 'CD', 'CD', 'NNP', 'NNP', 'NNP', '.', '</s>']\n",
      "Caps window ['lowercase', 'noinfo', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', '</s>']\n",
      "\n",
      "-------------------BEST NER LABEL MATCH--------------------\n",
      "\n",
      "indices counts = 7870\n",
      "ranked by best cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 33984\n",
      "KL divergence 0.04582437500357628\n",
      "FEATURES:   \"<unk>\", NNP, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', 'scorer', ':', 'vladimir', '<unk>', '(', '35th', ')', '</s>']\n",
      "PoS window  ['<s>', 'NNP', ':', 'NNP', 'NNP', '(', 'JJ', ')', '</s>']\n",
      "Caps window ['<s>', 'upperInitial', 'noinfo', 'upperInitial', 'upperInitial', 'noinfo', 'noinfo', 'noinfo', '</s>']\n",
      "\n",
      "ID 5804\n",
      "KL divergence 0.04582526162266731\n",
      "FEATURES:   \"markov\", NNP, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', '<s>', 'DG.', '<unk>', 'markov', '(', 'belarus', ')', 'DG.DGDG']\n",
      "PoS window  ['<s>', '<s>', 'CD', 'NNP', 'NNP', '(', 'NNP', ')', 'CD']\n",
      "Caps window ['<s>', '<s>', 'noinfo', 'upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo', 'noinfo']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('~/xyzzy.txt', 'w+') as f:\\n                        f.write(_14)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_obj.print_whole_report(k=2, print_window=True,\\\n",
    "                           gold_to_pred_counts=True, brief_summary=True, \\\n",
    "                           worst_overall=True, worst_ner_mismatch=True, \\\n",
    "                           worst_by_label=True, \\\n",
    "                           worst_hallucinations=True, worst_missed_ner=True, \\\n",
    "                           best_ner_match=True)\n",
    "\n",
    "\n",
    "\n",
    "# to save this report, do the following in a separate code chunk\n",
    "# use the following to write this report output to a text file\n",
    "# _14 means this is the 14th code chunk executed in this notebook\n",
    "\"\"\"\n",
    "with open('~/xyzzy.txt', 'w+') as f:\n",
    "                        f.write(_14)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### look at encoder loss here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------WORST RECONSTRUCTIONS-------------------------\n",
      "\n",
      "displaying top 3 results\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ID 20730\n",
      "reconstruction cosine proximity loss = 0.4873424584434484\n",
      "reconstruction GOLD word \"['filing']\"\n",
      "reconstruction PRED word \"['toured', 'celebrate', 'oasis', 'quartering', 'celebrations']\"\n",
      "\n",
      "word_window: ['<s>', '<s>', '<s>', 'ipo', 'filing', '--', '<unk>', '<unk>', 'inc']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ID 21724\n",
      "reconstruction cosine proximity loss = 0.4650989156958567\n",
      "reconstruction GOLD word \"['issuer']\"\n",
      "reconstruction PRED word \"['toured', 'oasis', 'celebrate', 'depopulated', 'revellers']\"\n",
      "\n",
      "word_window: ['<s>', '<s>', '<s>', '<s>', 'issuer', ':', 'bay', 'co', 'building']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ID 3087\n",
      "reconstruction cosine proximity loss = 0.45533098166510905\n",
      "reconstruction GOLD word \"['jeff']\"\n",
      "reconstruction PRED word \"['keenness', 'peacemaker', 'stabilising', 'u.s.-sponsored', 'arab']\"\n",
      "\n",
      "word_window: ['connection', '--', 'bad', 'boy', 'jeff', 'tarango', '.', '</s>', '</s>']\n",
      "\n",
      "-------------------------BEST RECONSTRUCTIONS--------------------------\n",
      "\n",
      "displaying top 3 results\n",
      "ID 47072\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "reconstruction cosine proximity loss = -0.5208270560997611\n",
      "reconstruction GOLD word \"['ankara']\"\n",
      "reconstruction PRED word \"['lagging', 'ankara', 'reassure', 'revive', 'sentiment']\"\n",
      "\n",
      "word_window: ['reuters', 'by', 'telephone', 'from', 'ankara', '.', '</s>', '</s>', '</s>']\n",
      "ID 46996\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "reconstruction cosine proximity loss = -0.4801432796351601\n",
      "reconstruction GOLD word \"['istanbul']\"\n",
      "reconstruction PRED word \"['lagging', 'coincided', 'ankara', 'istanbul', 'spurt']\"\n",
      "\n",
      "word_window: ['<s>', '<s>', '<s>', '<s>', 'istanbul', 'DGDGDGDG-DGDG-DGDG', '</s>', '</s>', '</s>']\n",
      "ID 27128\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "reconstruction cosine proximity loss = -0.47278955035486536\n",
      "reconstruction GOLD word \"['herzliya']\"\n",
      "reconstruction PRED word \"['reassure', 'lagging', 'revive', 'ankara', 'sentiment']\"\n",
      "\n",
      "word_window: ['<s>', '<s>', '<s>', '<s>', 'herzliya', ',', 'israel', 'DGDGDGDG-DGDG-DGDG', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# run this if decoder is on for CapsNet\n",
    "report_obj.print_eval_decoder_loss(k=3, nnk=5, print_embeddings=False, print_window=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just FYI -- more attributes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# gold labels\n",
    "print (\"devY\",devY.shape)\n",
    "# raw predictions made by a trained model on dev set\n",
    "print (\"dev_raw_y_pred\", dev_raw_y_pred.shape)\n",
    "# dev prediction labels\n",
    "print (\"dev_y_pred\", dev_y_pred.shape)\n",
    "# decoder on, decoder dev predictions\n",
    "# decoder off, empty\n",
    "print (\"dev_raw_y_pred_decoder_embeddings\",dev_raw_y_pred_decoder_embeddings.shape)\n",
    "\n",
    "report_obj.recall\n",
    "report_obj.precision\n",
    "report_obj.f1\n",
    "report_obj.gold_cts # gold label distribution\n",
    "report_obj.pred_cts # predicted label distribution\n",
    "# when gold is \"O\", but model thinks there is a NER tag\n",
    "report_obj.hallucination_idx \n",
    "# when gold is a NER tag, but model think it is \"O\"\n",
    "report_obj.missed_ner_idx\n",
    "# when both model and gold indicate a NER tag, and the tags matches\n",
    "report_obj.match_ner_idx\n",
    "# when both model and gold indicate a NER tag, and the tags mismatch\n",
    "report_obj.mismatch_ner_idx \n",
    "# dictionary[gold_label][prediction_label] --> data indices\n",
    "report_obj.gold_pred_idx_dict \n",
    "# dictionary[gold_label][prediction_label] --> count\n",
    "report_obj.gold_pred_ct_dict \n",
    "# dictionary[gold_label][prediction_label] --> data indices\n",
    "report_obj.gold_pred_idx_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brief_summary\n",
    "report_obj.print_brief_summary()\n",
    "\n",
    "# gold_to_pred_counts\n",
    "report_obj.print_gold_to_pred_counts(return_dict=False)\n",
    "\n",
    "# worst_overall\n",
    "report_obj.print_overall_rank(worst=True, k=5, print_window=True)\n",
    "\n",
    "# worst_ner_mismatch\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.mismatch_ner_idx, k=2, return_indices=False)\n",
    "\n",
    "# worst_by_label\n",
    "report_obj.print_rank_per_gold_label(worst=True, k=2, print_window=True)\n",
    "\n",
    "# worst_hallucinations\n",
    "# when gold is \"O\", but model thinks there is a NER tag\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.hallucination_idx, k=2, return_indices=False)\n",
    "\n",
    "# worst_missed_ner\n",
    "# when gold is a NER tag, but model think it is \"O\"\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.missed_ner_idx, k=5, return_indices=False)\n",
    "\n",
    "# best_ner_match\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.match_ner_idx, k=2, worst=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from common import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# Bokeh for plotting.\n",
    "utils.require_package(\"bokeh\")\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import LabelSet, HoverTool, WheelZoomTool\n",
    "bp.output_notebook()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 500\n",
    "Wv = embedding_matrix\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"word\", \"@desc\")])\n",
    "wztool = WheelZoomTool()\n",
    "fig = bp.figure(plot_width=600, plot_height=600, tools=[hover, wztool, 'pan', 'reset'])\n",
    "fig.toolbar.active_scroll = wztool\n",
    "df = bp.ColumnDataSource(dict(x=Wv[:n,0], y=Wv[:n,1], desc=vocabData.ids_to_words(range(n))))\n",
    "fig.circle('x', 'y', source=df)\n",
    "fig.add_layout(LabelSet(x='x', y='y', text='desc', source=df,\n",
    "                        x_offset=2, y_offset=2))\n",
    "bp.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
