{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load this section first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import evaluation_helper\n",
    "from loadutils import construct_embedding_matrix\n",
    "from loadutils import conll2003Data, loadDevPredictionsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "reading file from path ../data/conll2003/eng.train\n",
      "'readFile'  1270.15 ms\n",
      "----------------------------------------------------\n",
      "building vocabulary from TRAINING data...\n",
      "'buildVocab'  882.79 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  1437.07 ms\n",
      "----------------------------------------------------\n",
      "reading file from path ../data/conll2003/eng.testa\n",
      "'readFile'  199.86 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  263.70 ms\n",
      "----------------------------------------------------\n",
      "reading file from path ../data/conll2003/eng.testb\n",
      "'readFile'  181.21 ms\n",
      "----------------------------------------------------\n",
      "formatting sentences into input windows...\n",
      "'formatWindowedData'  435.70 ms\n",
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.50d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 50))\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE = \"../data/conll2003/eng.train\"\n",
    "DEV_FILE = \"../data/conll2003/eng.testa\"\n",
    "TEST_FILE = \"../data/conll2003/eng.testb\"\n",
    "\n",
    "global_max_features = 20000\n",
    "windowLength = 9\n",
    "global_embed_dim = 50\n",
    "#testNumSents = 20000\n",
    "\n",
    "# Use training set to build vocab here\n",
    "vocabData = conll2003Data(TRAIN_FILE)\n",
    "vocabData.buildVocab( vocabSize=global_max_features)\n",
    "\n",
    "# Format training data\n",
    "trainX, trainX_pos, trainX_capitals, trainY  = vocabData.formatWindowedData( \n",
    "                                                  vocabData.train_sentences, \n",
    "                                                  windowLength=windowLength,\n",
    "                                                  verbose=False)\n",
    "\n",
    "# read in dev data\n",
    "devSents = vocabData.readFile( DEV_FILE)\n",
    "devX, devX_pos, devX_capitals, devY = vocabData.formatWindowedData( \n",
    "                                              devSents, \n",
    "                                              windowLength=windowLength,\n",
    "                                              verbose=False)\n",
    "\n",
    "# read in the test data\n",
    "testSents = vocabData.readFile( TEST_FILE)\n",
    "testX, testX_pos, testX_capitals, testY = vocabData.formatWindowedData( \n",
    "                                                testSents, \n",
    "                                                windowLength=windowLength,\n",
    "                                                verbose=False)\n",
    "\n",
    "# load embeddings\n",
    "embedding_matrix = construct_embedding_matrix( global_embed_dim, \n",
    "                                               global_max_features, vocabData)\n",
    "\n",
    "\n",
    "# Get decoder Y -- 50 dim embedding of center word\n",
    "train_decoderY = embedding_matrix[trainX[:,4]]\n",
    "dev_decoderY = embedding_matrix[devX[:,4]]\n",
    "test_decoderY = embedding_matrix[testX[:,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo  - Quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rank 1\n",
      "modelName: encoder_2e_withsaving_again\n",
      "f1= 0.880151139449758\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.880151139449758"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(evaluation_helper)\n",
    "from evaluation_helper import get_f1_by_modelName, compare_models_by_f1\n",
    "\n",
    "modelName_list = ['encoder_2e_withsaving_again', 'encoder_2e_withsaving_again']\n",
    "compare_models_by_f1(modelName_list, y_true=devY, return_results=False)\n",
    "\n",
    "print (\"------------------------------------------------------------\")\n",
    "modelName1 = 'encoder_2e_withsaving_again'\n",
    "get_f1_by_modelName(modelName1, y_true=devY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty(0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo  - report class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(evaluation_helper)\n",
    "from evaluation_helper import EvalDev_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model predictions\n",
    "modelName = 'encoder_2e_withsaving_again'\n",
    "dev_raw_y_pred, dev_raw_y_pred_decoder_embeddings, dev_y_pred = loadDevPredictionsData(modelName)\n",
    "\n",
    "# construct report object\n",
    "report_obj = evaluation_helper.EvalDev_Report(modelName=modelName, y_true=devY, raw_y_pred=dev_raw_y_pred, y_pred=dev_y_pred, \\\n",
    "                                              y_true_decoder=dev_decoderY, y_pred_decoder=dev_raw_y_pred_decoder_embeddings) \n",
    "report_obj.connect_to_dataClass(vocabData)\n",
    "report_obj.connect_to_devData(devData=(devX, devX_pos, devX_capitals, devY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_raw_y_pred_decoder_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work on decoder reconstruction plot space tSNE\n",
    "\n",
    "if (dev_raw_y_pred_decoder_embeddings.ndim==2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------BRIEF SUMMARY-------------------------\n",
      "\n",
      "Model     encoder_2e_withsaving_again\n",
      "Precision 0.8943011397720456\n",
      "Recall    0.8664419388585377\n",
      "f1 score  0.880151139449758\n",
      "\n",
      "Gold NER label counts:\n",
      "42759 : ['O'] (tag3)\n",
      "2092 : ['I-ORG'] (tag5)\n",
      "2094 : ['I-LOC'] (tag6)\n",
      "1264 : ['I-MISC'] (tag7)\n",
      "3149 : ['I-PER'] (tag4)\n",
      "4 : ['B-MISC'] (tag8)\n",
      "\n",
      "Predicted NER label counts:\n",
      "43027 : ['O'] (tag3)\n",
      "2226 : ['I-LOC'] (tag6)\n",
      "1005 : ['I-MISC'] (tag7)\n",
      "3241 : ['I-PER'] (tag4)\n",
      "1863 : ['I-ORG'] (tag5)\n",
      "\n",
      "----------------GOLD to PREDICTION LABELS COUNTS---------------\n",
      "\n",
      "\n",
      "Gold label \"['O']\" (tag3), prediction label counts:\n",
      "42601 (0.9963%): \"['O']\" (tag3)\n",
      "40 (0.0009%): \"['I-PER']\" (tag4)\n",
      "75 (0.0018%): \"['I-ORG']\" (tag5)\n",
      "11 (0.0003%): \"['I-LOC']\" (tag6)\n",
      "32 (0.0007%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-PER']\" (tag4), prediction label counts:\n",
      "45 (0.0143%): \"['O']\" (tag3)\n",
      "3021 (0.9594%): \"['I-PER']\" (tag4)\n",
      "64 (0.0203%): \"['I-ORG']\" (tag5)\n",
      "17 (0.0054%): \"['I-LOC']\" (tag6)\n",
      "2 (0.0006%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-ORG']\" (tag5), prediction label counts:\n",
      "173 (0.0827%): \"['O']\" (tag3)\n",
      "115 (0.055%): \"['I-PER']\" (tag4)\n",
      "1579 (0.7548%): \"['I-ORG']\" (tag5)\n",
      "186 (0.0889%): \"['I-LOC']\" (tag6)\n",
      "39 (0.0186%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-LOC']\" (tag6), prediction label counts:\n",
      "36 (0.0172%): \"['O']\" (tag3)\n",
      "32 (0.0153%): \"['I-PER']\" (tag4)\n",
      "55 (0.0263%): \"['I-ORG']\" (tag5)\n",
      "1948 (0.9303%): \"['I-LOC']\" (tag6)\n",
      "23 (0.011%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['I-MISC']\" (tag7), prediction label counts:\n",
      "172 (0.1361%): \"['O']\" (tag3)\n",
      "33 (0.0261%): \"['I-PER']\" (tag4)\n",
      "89 (0.0704%): \"['I-ORG']\" (tag5)\n",
      "64 (0.0506%): \"['I-LOC']\" (tag6)\n",
      "906 (0.7168%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-MISC']\" (tag8), prediction label counts:\n",
      "0 (0.0%): \"['O']\" (tag3)\n",
      "0 (0.0%): \"['I-PER']\" (tag4)\n",
      "1 (0.25%): \"['I-ORG']\" (tag5)\n",
      "0 (0.0%): \"['I-LOC']\" (tag6)\n",
      "3 (0.75%): \"['I-MISC']\" (tag7)\n",
      "0 (0.0%): \"['B-MISC']\" (tag8)\n",
      "0 (0.0%): \"['B-ORG']\" (tag9)\n",
      "0 (0.0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-ORG']\" (tag9), prediction label counts:\n",
      "0 (0%): \"['O']\" (tag3)\n",
      "0 (0%): \"['I-PER']\" (tag4)\n",
      "0 (0%): \"['I-ORG']\" (tag5)\n",
      "0 (0%): \"['I-LOC']\" (tag6)\n",
      "0 (0%): \"['I-MISC']\" (tag7)\n",
      "0 (0%): \"['B-MISC']\" (tag8)\n",
      "0 (0%): \"['B-ORG']\" (tag9)\n",
      "0 (0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "Gold label \"['B-LOC']\" (tag10), prediction label counts:\n",
      "0 (0%): \"['O']\" (tag3)\n",
      "0 (0%): \"['I-PER']\" (tag4)\n",
      "0 (0%): \"['I-ORG']\" (tag5)\n",
      "0 (0%): \"['I-LOC']\" (tag6)\n",
      "0 (0%): \"['I-MISC']\" (tag7)\n",
      "0 (0%): \"['B-MISC']\" (tag8)\n",
      "0 (0%): \"['B-ORG']\" (tag9)\n",
      "0 (0%): \"['B-LOC']\" (tag10)\n",
      "\n",
      "-------------------------WORST OVERALL-------------------------\n",
      "\n",
      "indices counts = 51362\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 40660\n",
      "KL divergence 8.691455841064453\n",
      "FEATURES:   \"i\", PRP, allCaps\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['-', 'belgian', 'king', '<unk>', 'i', 'born', '.', '</s>', '</s>']\n",
      "PoS window  [':', 'JJ', 'NNP', 'NNP', 'PRP', 'VBN', '.', '</s>', '</s>']\n",
      "Caps window ['noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'allCaps', 'lowercase', 'noinfo', '</s>', '</s>']\n",
      "\n",
      "ID 32072\n",
      "KL divergence 8.6408109664917\n",
      "FEATURES:   \"jr\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', 'DG.', 'al', '<unk>', 'jr', '(', 'u.s.', ')', ',']\n",
      "PoS window  ['<s>', 'CD', 'NNP', 'NNP', 'NNP', '(', 'NNP', ')', ',']\n",
      "Caps window ['<s>', 'noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', 'noinfo', 'noinfo', 'noinfo']\n",
      "\n",
      "-------------------WORST NER LABEL MISMATCH--------------------\n",
      "\n",
      "indices counts = 723\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 21875\n",
      "KL divergence 6.258211135864258\n",
      "FEATURES:   \"j.j.\", NNP, noinfo\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['competitive', 'pre-sale', 'contributed', 'by', 'j.j.', 'kenny', 'k-sheets', ':', '</s>']\n",
      "PoS window  ['JJ', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNS', ':', '</s>']\n",
      "Caps window ['allCaps', 'noinfo', 'allCaps', 'allCaps', 'noinfo', 'allCaps', 'noinfo', 'noinfo', '</s>']\n",
      "\n",
      "ID 32032\n",
      "KL divergence 5.501535415649414\n",
      "FEATURES:   \"<unk>\", VB, upperInitial\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['(', 'u.s.', ')', ',', '<unk>', '<unk>', ',', 'DGDG.DGDGDG', '</s>']\n",
      "PoS window  ['(', 'NNP', ')', ',', 'VB', 'NNP', ',', 'CD', '</s>']\n",
      "Caps window ['noinfo', 'noinfo', 'noinfo', 'noinfo', 'upperInitial', 'noinfo', 'noinfo', 'noinfo', '</s>']\n",
      "\n",
      "----------------WORST NER PREDICTION BY LABEL------------------\n",
      "\n",
      "----------------------------\n",
      "Label O (tag3)\n",
      "indices counts = 42759\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 32072\n",
      "KL divergence 8.6408109664917\n",
      "FEATURES:   \"jr\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', 'DG.', 'al', '<unk>', 'jr', '(', 'u.s.', ')', ',']\n",
      "PoS window  ['<s>', 'CD', 'NNP', 'NNP', 'NNP', '(', 'NNP', ')', ',']\n",
      "Caps window ['<s>', 'noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', 'noinfo', 'noinfo', 'noinfo']\n",
      "\n",
      "ID 48287\n",
      "KL divergence 6.297656059265137\n",
      "FEATURES:   \"<unk>\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['bag', 'safety', ':', 'everyone', '<unk>', ',', 'kids', 'in', 'back']\n",
      "PoS window  ['NNP', 'NNP', ':', 'NN', 'NNP', ',', 'NNPS', 'IN', 'RB']\n",
      "Caps window ['upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'lowercase', 'upperInitial']\n",
      "----------------------------\n",
      "Label I-PER (tag4)\n",
      "indices counts = 3149\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 40660\n",
      "KL divergence 8.691455841064453\n",
      "FEATURES:   \"i\", PRP, allCaps\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['-', 'belgian', 'king', '<unk>', 'i', 'born', '.', '</s>', '</s>']\n",
      "PoS window  [':', 'JJ', 'NNP', 'NNP', 'PRP', 'VBN', '.', '</s>', '</s>']\n",
      "Caps window ['noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'allCaps', 'lowercase', 'noinfo', '</s>', '</s>']\n",
      "\n",
      "ID 45700\n",
      "KL divergence 7.806224346160889\n",
      "FEATURES:   \"than\", IN, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['<s>', '<s>', '<s>', '<unk>', 'than', ',', 'an', 'elected', 'member']\n",
      "PoS window  ['<s>', '<s>', '<s>', 'NNP', 'IN', ',', 'DT', 'VBN', 'NN']\n",
      "Caps window ['<s>', '<s>', '<s>', 'upperInitial', 'upperInitial', 'noinfo', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label I-ORG (tag5)\n",
      "indices counts = 2092\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 21875\n",
      "KL divergence 6.258211135864258\n",
      "FEATURES:   \"j.j.\", NNP, noinfo\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['competitive', 'pre-sale', 'contributed', 'by', 'j.j.', 'kenny', 'k-sheets', ':', '</s>']\n",
      "PoS window  ['JJ', 'NN', 'NNP', 'NNP', 'NNP', 'NNP', 'NNS', ':', '</s>']\n",
      "Caps window ['allCaps', 'noinfo', 'allCaps', 'allCaps', 'noinfo', 'allCaps', 'noinfo', 'noinfo', '</s>']\n",
      "\n",
      "ID 9152\n",
      "KL divergence 5.600708484649658\n",
      "FEATURES:   \"ministry\", NN, lowercase\n",
      "Gold NER    ['I-ORG']\n",
      "Pred NER    ['O']\n",
      "Text window [')', '\"', 'but', 'interior', 'ministry', 'officials', 'had', 'consistently', 'said']\n",
      "PoS window  [')', '\"', 'CC', 'JJ', 'NN', 'NNS', 'VBD', 'RB', 'VBD']\n",
      "Caps window ['noinfo', 'noinfo', 'lowercase', 'lowercase', 'lowercase', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label I-LOC (tag6)\n",
      "indices counts = 2094\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 48267\n",
      "KL divergence 5.587638854980469\n",
      "FEATURES:   \"DGDG\", CD, noinfo\n",
      "Gold NER    ['I-LOC']\n",
      "Pred NER    ['O']\n",
      "Text window [',', '<unk>', 'DGDG', 'and', 'DGDG', 'in', 'the', 'midwest', 'and']\n",
      "PoS window  [',', 'NNP', 'CD', 'CC', 'CD', 'IN', 'DT', 'NNP', 'CC']\n",
      "Caps window ['noinfo', 'upperInitial', 'noinfo', 'lowercase', 'noinfo', 'lowercase', 'lowercase', 'upperInitial', 'lowercase']\n",
      "\n",
      "ID 48273\n",
      "KL divergence 5.480287551879883\n",
      "FEATURES:   \"DG\", CD, noinfo\n",
      "Gold NER    ['I-LOC']\n",
      "Pred NER    ['O']\n",
      "Text window ['the', 'midwest', 'and', '<unk>', 'DG', 'in', 'california', '.', '</s>']\n",
      "PoS window  ['DT', 'NNP', 'CC', 'NNP', 'CD', 'IN', 'NNP', '.', '</s>']\n",
      "Caps window ['lowercase', 'upperInitial', 'lowercase', 'upperInitial', 'noinfo', 'lowercase', 'upperInitial', 'noinfo', '</s>']\n",
      "----------------------------\n",
      "Label I-MISC (tag7)\n",
      "indices counts = 1264\n",
      "ranked by worst cross-entropy loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 2 results\n",
      "\n",
      "ID 6691\n",
      "KL divergence 6.303609848022461\n",
      "FEATURES:   \"<unk>\", JJ, noinfo\n",
      "Gold NER    ['I-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['<s>', 'the', 'move', 'to', '<unk>', 'atalanta', '<unk>', '<unk>', ',']\n",
      "PoS window  ['<s>', 'DT', 'NN', 'TO', 'JJ', 'NNP', 'VBZ', 'NNP', ',']\n",
      "Caps window ['<s>', 'upperInitial', 'lowercase', 'lowercase', 'noinfo', 'upperInitial', 'lowercase', 'upperInitial', 'noinfo']\n",
      "\n",
      "ID 43588\n",
      "KL divergence 5.999802589416504\n",
      "FEATURES:   \"division\", NN, lowercase\n",
      "Gold NER    ['I-MISC']\n",
      "Pred NER    ['O']\n",
      "Text window ['<s>', '<s>', '\"', 'this', 'division', 'would', 'guarantee', 'a', '<unk>']\n",
      "PoS window  ['<s>', '<s>', '\"', 'DT', 'NN', 'MD', 'VB', 'DT', 'NN']\n",
      "Caps window ['<s>', '<s>', 'noinfo', 'upperInitial', 'lowercase', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "----------------------------\n",
      "Label B-MISC (tag8)\n",
      "indices counts = 4\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 42100\n",
      "KL divergence 4.277178764343262\n",
      "FEATURES:   \"<unk>\", NNPS, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['I-ORG']\n",
      "Text window ['<s>', '<s>', 's.', 'african', '<unk>', 'still', 'seek', 'own', 'territory']\n",
      "PoS window  ['<s>', '<s>', 'NNP', 'NNP', 'NNPS', 'RB', 'VBP', 'JJ', 'NN']\n",
      "Caps window ['<s>', '<s>', 'noinfo', 'upperInitial', 'upperInitial', 'lowercase', 'lowercase', 'lowercase', 'lowercase']\n",
      "\n",
      "ID 42654\n",
      "KL divergence 3.0099031925201416\n",
      "FEATURES:   \"hutu\", NNP, upperInitial\n",
      "Gold NER    ['B-MISC']\n",
      "Pred NER    ['I-MISC']\n",
      "Text window ['the', 'DG.DG', 'million', 'rwandan', 'hutu', 'refugees', 'in', 'zaire', 'and']\n",
      "PoS window  ['DT', 'CD', 'CD', 'NNP', 'NNP', 'NNS', 'IN', 'NNP', 'CC']\n",
      "Caps window ['lowercase', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'lowercase', 'lowercase', 'upperInitial', 'lowercase']\n",
      "----------------------------\n",
      "Label B-ORG (tag9)\n",
      "indices counts = 0\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "empty -- no predictions were made\n",
      "----------------------------\n",
      "Label B-LOC (tag10)\n",
      "indices counts = 0\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "empty -- no predictions were made\n",
      "\n",
      "-------------------------HALLUCINATIONS------------------------\n",
      "model predicts a NER label, but gold label shows None\n",
      "\n",
      "indices counts = 158\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 32072\n",
      "KL divergence 8.6408109664917\n",
      "FEATURES:   \"jr\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', 'DG.', 'al', '<unk>', 'jr', '(', 'u.s.', ')', ',']\n",
      "PoS window  ['<s>', 'CD', 'NNP', 'NNP', 'NNP', '(', 'NNP', ')', ',']\n",
      "Caps window ['<s>', 'noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'noinfo', 'noinfo', 'noinfo', 'noinfo']\n",
      "\n",
      "ID 48287\n",
      "KL divergence 6.297656059265137\n",
      "FEATURES:   \"<unk>\", NNP, upperInitial\n",
      "Gold NER    ['O']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['bag', 'safety', ':', 'everyone', '<unk>', ',', 'kids', 'in', 'back']\n",
      "PoS window  ['NNP', 'NNP', ':', 'NN', 'NNP', ',', 'NNPS', 'IN', 'RB']\n",
      "Caps window ['upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'lowercase', 'upperInitial']\n",
      "\n",
      "----------------------MISSED NER LABELS------------------------\n",
      "model predicts no NER label, but gold label shows a NER class\n",
      "\n",
      "indices counts = 426\n",
      "ranked by worst cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 40660\n",
      "KL divergence 8.691455841064453\n",
      "FEATURES:   \"i\", PRP, allCaps\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['-', 'belgian', 'king', '<unk>', 'i', 'born', '.', '</s>', '</s>']\n",
      "PoS window  [':', 'JJ', 'NNP', 'NNP', 'PRP', 'VBN', '.', '</s>', '</s>']\n",
      "Caps window ['noinfo', 'upperInitial', 'upperInitial', 'upperInitial', 'allCaps', 'lowercase', 'noinfo', '</s>', '</s>']\n",
      "\n",
      "ID 45700\n",
      "KL divergence 7.806224346160889\n",
      "FEATURES:   \"than\", IN, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['O']\n",
      "Text window ['<s>', '<s>', '<s>', '<unk>', 'than', ',', 'an', 'elected', 'member']\n",
      "PoS window  ['<s>', '<s>', '<s>', 'NNP', 'IN', ',', 'DT', 'VBN', 'NN']\n",
      "Caps window ['<s>', '<s>', '<s>', 'upperInitial', 'upperInitial', 'noinfo', 'lowercase', 'lowercase', 'lowercase']\n",
      "\n",
      "-------------------BEST NER LABEL MISMATCH--------------------\n",
      "\n",
      "indices counts = 7454\n",
      "ranked by best cross-entropy loss\n",
      "top 2 results\n",
      "\n",
      "ID 35580\n",
      "FEATURES:   \"naoko\", NNP, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['(', 'switzerland', ')', 'beat', 'naoko', 'kijimuta', '(', 'japan', ')']\n",
      "PoS window  ['(', 'NNP', ')', 'VB', 'NNP', 'NNP', '(', 'NNP', ')']\n",
      "Caps window ['noinfo', 'upperInitial', 'noinfo', 'lowercase', 'upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo']\n",
      "\n",
      "ID 5975\n",
      "FEATURES:   \"sigurd\", NNP, upperInitial\n",
      "Gold NER    ['I-PER']\n",
      "Pred NER    ['I-PER']\n",
      "Text window ['<s>', '<s>', '<s>', 'DG.', 'sigurd', 'njerve', '(', 'norway', ')']\n",
      "PoS window  ['<s>', '<s>', '<s>', 'NNP', 'NNP', 'NNP', '(', 'NNP', ')']\n",
      "Caps window ['<s>', '<s>', '<s>', 'noinfo', 'upperInitial', 'upperInitial', 'noinfo', 'upperInitial', 'noinfo']\n"
     ]
    }
   ],
   "source": [
    "report_obj.print_whole_report(k=2, print_window=False)\n",
    "\n",
    "# to save this report, do the following in a separate code chunk\n",
    "# use the following to write this report output to a text file\n",
    "# _14 means this is the 14th code chunk executed in this notebook\n",
    "\"\"\"\n",
    "with open('~/xyzzy.txt', 'w+') as f:\n",
    "                        f.write(_14)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just FYI -- more attributes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# gold labels\n",
    "print (\"devY\",devY.shape)\n",
    "# raw predictions made by a trained model on dev set\n",
    "print (\"dev_raw_y_pred\", dev_raw_y_pred.shape)\n",
    "# dev prediction labels\n",
    "print (\"dev_y_pred\", dev_y_pred.shape)\n",
    "# decoder on, decoder dev predictions\n",
    "# decoder off, empty\n",
    "print (\"dev_raw_y_pred_decoder_embeddings\",dev_raw_y_pred_decoder_embeddings.shape)\n",
    "\n",
    "report_obj.recall\n",
    "report_obj.precision\n",
    "report_obj.f1\n",
    "report_obj.gold_cts # gold label distribution\n",
    "report_obj.pred_cts # predicted label distribution\n",
    "# when gold is \"O\", but model thinks there is a NER tag\n",
    "report_obj.hallucination_idx \n",
    "# when gold is a NER tag, but model think it is \"O\"\n",
    "report_obj.missed_ner_idx\n",
    "# when both model and gold indicate a NER tag, and the tags matches\n",
    "report_obj.match_ner_idx\n",
    "# when both model and gold indicate a NER tag, and the tags mismatch\n",
    "report_obj.mismatch_ner_idx \n",
    "# dictionary[gold_label][prediction_label] --> data indices\n",
    "report_obj.gold_pred_idx_dict \n",
    "# dictionary[gold_label][prediction_label] --> count\n",
    "report_obj.gold_pred_ct_dict \n",
    "# dictionary[gold_label][prediction_label] --> data indices\n",
    "report_obj.gold_pred_idx_dict "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# brief_summary\n",
    "report_obj.print_brief_summary()\n",
    "\n",
    "# gold_to_pred_counts\n",
    "report_obj.print_gold_to_pred_counts(return_dict=False)\n",
    "\n",
    "# worst_overall\n",
    "report_obj.print_overall_rank(worst=True, k=5, print_window=True)\n",
    "\n",
    "# worst_ner_mismatch\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.mismatch_ner_idx, k=2, return_indices=False)\n",
    "\n",
    "# worst_by_label\n",
    "report_obj.print_rank_per_gold_label(worst=True, k=2, print_window=True)\n",
    "\n",
    "# worst_hallucinations\n",
    "# when gold is \"O\", but model thinks there is a NER tag\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.hallucination_idx, k=2, return_indices=False)\n",
    "\n",
    "# worst_missed_ner\n",
    "# when gold is a NER tag, but model think it is \"O\"\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.missed_ner_idx, k=5, return_indices=False)\n",
    "\n",
    "# best_ner_match\n",
    "report_obj.print_idxlist_to_textlists(idx_list=report_obj.match_ner_idx, k=2, worst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these two tags were never used\n",
      "['B-ORG']\n",
      "['B-LOC']\n"
     ]
    }
   ],
   "source": [
    "print (\"these two tags were never used\")\n",
    "print (report_obj.nerTags.ids_to_words([9]))\n",
    "print (report_obj.nerTags.ids_to_words([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore this section"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Get X pos tags\n",
    "\n",
    "# encoding 1-hot for pos tags\n",
    "trainX_pos_cat = to_categorical(trainX_pos.astype('float32'))\n",
    "devX_pos_cat = to_categorical(devX_pos.astype('float32'), num_classes=trainX_pos_cat.shape[2]) \n",
    "testX_pos_cat = to_categorical(testX_pos.astype('float32'), num_classes=trainX_pos_cat.shape[2])\n",
    "\n",
    "trainX_pos_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), trainX_pos_cat)), dtype=np.float)\n",
    "devX_pos_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), devX_pos_cat)), dtype=np.float)\n",
    "testX_pos_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), testX_pos_cat)), dtype=np.float)\n",
    "\n",
    "\n",
    "# Get X capitlization \n",
    "\n",
    "# encoding 1-hot for capitalization info  (\"allCaps\", \"upperInitial\", \"lowercase\", \"mixedCaps\", \"noinfo\")\n",
    "trainX_capitals_cat = to_categorical(trainX_capitals.astype('float32'))\n",
    "devX_capitals_cat = to_categorical(devX_capitals.astype('float32'), num_classes=trainX_capitals_cat.shape[2]) \n",
    "testX_capitals_cat = to_categorical(testX_capitals.astype('float32'), num_classes=trainX_capitals_cat.shape[2])\n",
    "\n",
    "trainX_capitals_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), trainX_capitals_cat)), dtype=np.float)\n",
    "devX_capitals_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), devX_capitals_cat)), dtype=np.float)\n",
    "testX_capitals_cat = np.array(list(map( lambda i: np.array(i[:,3:], dtype=np.float), testX_capitals_cat)), dtype=np.float)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "from keras import callbacks, optimizers\n",
    "from keras import backend as KB\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Activation\n",
    "from keras.layers import LeakyReLU, Dense, Input, Embedding, Dropout, Reshape, Concatenate, MaxPooling1D, Flatten\n",
    "from keras.layers import Bidirectional, GRU, Flatten, SpatialDropout1D, Conv1D\n",
    "from keras.layers import Add\n",
    "# from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from common import vocabulary, utils\n",
    "\n",
    "# capsule layers from Xifeng Guo \n",
    "# https://github.com/XifengGuo/CapsNet-Keras\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "import glove_helper\n",
    "\n",
    "import time # !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
